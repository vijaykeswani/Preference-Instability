## Moral Preference Instability Quantification and Its Impact on AI Alignment

This repository contains data collected and analysis conducted for the purpose of investigating *moral preference instability*.

To collect the data, we conducted online surveys to obtain people's preferences regarding kidney transplant allocation. Participants were provided with several pairwise comparisons of kidney patients and asked to decide which of the presented patients should receive an available kidney. Their responses were then used to quantify changes in their responses across sessions and model revisions to their decision-making process over time.

Study 1&2 were performed with a relatively smaller feature set and contained a limited number of participants (<50). Our findings from these studies were published in the AIES 2024 paper ***"On The Stability of Moral Preferences: A Problem with Computational Elicitation Methods"***. The corresponding folder for these studies contains the data and code used to generate the paper's results.

Study 3 expanded the data collection and analysis effort to a significantly larger number of participants (>400).  The corresponding folder contains the data and code for the analysis of this larger data collection effort to assess moral preference instability. Additionally, this analysis also assesses the performance of AI modeling approaches in achieving preference alignment when faced with instability. The findings from this will appear in the AAAI 2026 paper ***"Moral Change or Noise? On Problems of Aligning AI With Temporally Unstable Human Feedback"***.

